{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0g1pF6RfViPr"
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL_FILENAME = \"saved_model\"\n",
    "FLOAT_TFL_MODEL_FILENAME = \"float_model.tfl\"\n",
    "QUANTIZED_TFL_MODEL_FILENAME = \"quantized_model.tfl\"\n",
    "TFL_CC_MODEL_FILENAME = \"magic_wand_model_data.cc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvPo0OP0TFDq",
    "outputId": "bd434b10-f2e0-424d-d7d9-b921b0d5eb27"
   },
   "outputs": [],
   "source": [
    "# !curl -L https://github.com/petewarden/magic_wand_digit_data/archive/8170591863f9addca27b1a963263f7c7bed33f41.zip -o magic_wand_digit_data.zip\n",
    "# !unzip magic_wand_digit_data.zip\n",
    "# !rm -rf magic_wand_digit_data\n",
    "# !mv magic_wand_digit_data-* magic_wand_digit_data\n",
    "# !rm -rf magic_wand_digit_data.zip\n",
    "# !rm -rf sample_data\n",
    "# !mkdir -p checkpoints\n",
    "#!pip install tensorflow\n",
    "#!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mWO58-igVFSd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400 strokes from Server dataset.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "SERVER_DATA_DIR = \"Data/final_dataset_800/server\"\n",
    "\n",
    "strokes = []\n",
    "for filename in glob.glob(os.path.join(SERVER_DATA_DIR, \"*\", \"*.json\")):\n",
    "  with open(filename, \"r\") as file:\n",
    "    file_contents = file.read()\n",
    "  file_data = json.loads(file_contents)\n",
    "  for stroke in file_data[\"strokes\"]:\n",
    "    stroke[\"filename\"] = filename\n",
    "    strokes.append(stroke)\n",
    "      \n",
    "print(f\"Loaded {len(strokes)} strokes from Server dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xfLzrpyLVJ5S"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_stroke(stroke):\n",
    "\n",
    "  x_array = []\n",
    "  y_array = []\n",
    "  for coords in stroke[\"strokePoints\"]:\n",
    "    x_array.append(coords[\"x\"])\n",
    "    y_array.append(coords[\"y\"])\n",
    "\n",
    "  fig = plt.figure(figsize=(12.8, 4.8))\n",
    "  fig.suptitle(stroke[\"label\"])\n",
    "\n",
    "  ax = fig.add_subplot(131)\n",
    "  ax.set_xlabel('x')\n",
    "  ax.set_ylabel('y')\n",
    "  ax.set_xlim(-0.4, 0.4)\n",
    "  ax.set_ylim(-0.4, 0.4)\n",
    "  ax.plot(x_array, y_array)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "dveZd2ZuW-jl",
    "outputId": "df5428b1-af03-4ad7-f6fa-0cafdf0cb727"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for i in range(0, 900):\n",
    "plot_stroke(strokes[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3FVPj-eqjvoB"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "FIXED_POINT = 256\n",
    "\n",
    "def mul_fp(a, b):\n",
    "  return (a * b) / FIXED_POINT\n",
    "\n",
    "def div_fp(a, b):\n",
    "  if b == 0:\n",
    "    b = 1\n",
    "  return (a * FIXED_POINT) / b\n",
    "\n",
    "def float_to_fp(a):\n",
    "  return math.floor(a * FIXED_POINT)\n",
    "\n",
    "def norm_to_coord_fp(a, range_fp, half_size_fp):\n",
    "  a_fp = float_to_fp(a)\n",
    "  norm_fp = div_fp(a_fp, range_fp)\n",
    "  return mul_fp(norm_fp, half_size_fp) + half_size_fp\n",
    "\n",
    "def round_fp_to_int(a):\n",
    "  return math.floor((a + (FIXED_POINT / 2)) / FIXED_POINT)\n",
    "\n",
    "def gate(a, min, max):\n",
    "  if a < min:\n",
    "    return min\n",
    "  elif a > max:\n",
    "    return max\n",
    "  else:\n",
    "    return a\n",
    "\n",
    "def rasterize_stroke(stroke_points, x_range, y_range, width, height):\n",
    "  num_channels = 3\n",
    "  buffer_byte_count = height * width * num_channels\n",
    "  buffer = bytearray(buffer_byte_count)\n",
    "\n",
    "  width_fp = width * FIXED_POINT\n",
    "  height_fp = height * FIXED_POINT\n",
    "  half_width_fp = width_fp / 2\n",
    "  half_height_fp = height_fp / 2\n",
    "  x_range_fp = float_to_fp(x_range)\n",
    "  y_range_fp = float_to_fp(y_range)\n",
    "\n",
    "  t_inc_fp = FIXED_POINT / len(stroke_points)\n",
    "\n",
    "  one_half_fp = (FIXED_POINT / 2)\n",
    "\n",
    "  for point_index in range(len(stroke_points) - 1):\n",
    "    start_point = stroke_points[point_index]\n",
    "    end_point = stroke_points[point_index + 1]\n",
    "    start_x_fp = norm_to_coord_fp(start_point[\"x\"], x_range_fp, half_width_fp)\n",
    "    start_y_fp = norm_to_coord_fp(-start_point[\"y\"], y_range_fp, half_height_fp)\n",
    "    end_x_fp = norm_to_coord_fp(end_point[\"x\"], x_range_fp, half_width_fp)\n",
    "    end_y_fp = norm_to_coord_fp(-end_point[\"y\"], y_range_fp, half_height_fp)\n",
    "    delta_x_fp = end_x_fp - start_x_fp\n",
    "    delta_y_fp = end_y_fp - start_y_fp\n",
    "\n",
    "    t_fp = point_index * t_inc_fp\n",
    "    if t_fp < one_half_fp:\n",
    "      local_t_fp = div_fp(t_fp, one_half_fp)\n",
    "      one_minus_t_fp = FIXED_POINT - local_t_fp\n",
    "      red = round_fp_to_int(one_minus_t_fp * 255)\n",
    "      green = round_fp_to_int(local_t_fp * 255)\n",
    "      blue = 0\n",
    "    else:\n",
    "      local_t_fp = div_fp(t_fp - one_half_fp, one_half_fp)\n",
    "      one_minus_t_fp = FIXED_POINT - local_t_fp\n",
    "      red = 0\n",
    "      green = round_fp_to_int(one_minus_t_fp * 255)\n",
    "      blue = round_fp_to_int(local_t_fp * 255)\n",
    "    red = gate(red, 0, 255)\n",
    "    green = gate(green, 0, 255)\n",
    "    blue = gate(blue, 0, 255)\n",
    "\n",
    "    if abs(delta_x_fp) > abs(delta_y_fp):\n",
    "      line_length = abs(round_fp_to_int(delta_x_fp))\n",
    "      if delta_x_fp > 0:\n",
    "        x_inc_fp = 1 * FIXED_POINT\n",
    "        y_inc_fp = div_fp(delta_y_fp, delta_x_fp)\n",
    "      else:\n",
    "        x_inc_fp = -1 * FIXED_POINT\n",
    "        y_inc_fp = -div_fp(delta_y_fp, delta_x_fp)\n",
    "    else:\n",
    "      line_length = abs(round_fp_to_int(delta_y_fp))\n",
    "      if delta_y_fp > 0:\n",
    "        y_inc_fp = 1 * FIXED_POINT\n",
    "        x_inc_fp = div_fp(delta_x_fp, delta_y_fp)\n",
    "      else:\n",
    "        y_inc_fp = -1 * FIXED_POINT\n",
    "        x_inc_fp = -div_fp(delta_x_fp, delta_y_fp)\n",
    "    for i in range(line_length + 1):\n",
    "      x_fp = start_x_fp + (i * x_inc_fp)\n",
    "      y_fp = start_y_fp + (i * y_inc_fp)\n",
    "      x = round_fp_to_int(x_fp)\n",
    "      y = round_fp_to_int(y_fp)\n",
    "      if (x < 0) or (x >= width) or (y < 0) or (y >= height):\n",
    "        continue\n",
    "      buffer_index = (y * width * num_channels) + (x * num_channels)\n",
    "      buffer[buffer_index + 0] = red\n",
    "      buffer[buffer_index + 1] = green\n",
    "      buffer[buffer_index + 2] = blue\n",
    "  \n",
    "  np_buffer = np.frombuffer(buffer, dtype=np.uint8).reshape(height, width, num_channels)\n",
    "\n",
    "  return np_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "sOaxOIjRskJg",
    "outputId": "ac2b4c02-1a39-4be8-bb7b-41930ed133b1"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAAUVklEQVR4Ae3dPcusVxUG4PfkDEZIUPwAFSSWFomCPyDYeZCg8RfYKUTwKxr8AlEUP2I0anEEBZv8gqioaQO2Fhot7BKbKElQUTFhTrCxGA7v+zC3z97sZ6/nSjWZWe/ae11rwp1pZi4u/EOAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIFBZ4Frl4cxGgMA6gff8Nvv74yGr//27s3rVbQXuaNtONwIECBCYRUAAzLIp9yRAgEBjAQHQGFQ7AgQIzCIgAGbZlHsSIECgsYAAaAyqHQECBGYREACzbMo9CRAg0FhAADQG1Y4AAQKzCAiAWTblngQIEGgsIAAag2pHgACBWQQEwCybck8CBAg0FhAAjUG1I0CAwCwCAmCWTbknAQIEGgsIgMag2hEgQGAWAQEwy6bckwABAo0FBEBjUO0IECAwi0D47d3/x1j3PpP90R/uy+pVtxX42Qeyfh/8eVaveqjA/U9nx//lrqz+cMzqVY8V8AlgrL/TCRAgMExAAAyjdzABAgTGCgiAsf5OJ0CAwDABATCM3sEECBAYKyAAxvo7nQABAsMEBMAwegcTIEBgrIAAGOvvdAIECAwTEADD6B1MgACBsQICYKy/0wkQIDBMQAAMo3cwAQIExgoIgLH+TidAgMAwAQEwjN7BBAgQGCsgAMb6O50AAQLDBATAMHoHEyBAYKyAABjr73QCBAgME8h/D+Dtf84u+/J/snrVbQWevj/r90L+lsgOUD1S4LXhf47H8O3wp3eOnM7ZqYBPAKmYegIECBQREABFFmkMAgQIpAICIBVTT4AAgSICAqDIIo1BgACBVEAApGLqCRAgUERAABRZpDEIECCQCgiAVEw9AQIEiggIgCKLNAYBAgRSAQGQiqknQIBAEQEBUGSRxiBAgEAqIABSMfUECBAoIiAAiizSGAQIEEgFBEAqpp4AAQJFBARAkUUagwABAqmAAEjF1BMgQKCIwOHigV9ko/zm7qz+hTdn9arbCvT+Avi2t9UtFHj/L7M/+NX7svp7ns3qVc8l4BPAXPtyWwIECDQTEADNKDUiQIDAXAICYK59uS0BAgSaCQiAZpQaESBAYC4BATDXvtyWAAECzQQEQDNKjQgQIDCXgACYa19uS4AAgWYCAqAZpUYECBCYS0AAzLUvtyVAgEAzAQHQjFIjAgQIzCUgAObal9sSIECgmYAAaEapEQECBOYSEABz7cttCRAg0ExAADSj1IgAAQJzCQiAufbltgQIEGgmcLg4HLNmf3tDVq+6rcDv3pX1O4b7PR6y/qqHCqT/+abf7//cO4aO5/DOAj4BdAbWngABAlsVEABb3Yx7ESBAoLOAAOgMrD0BAgS2KiAAtroZ9yJAgEBnAQHQGVh7AgQIbFVAAGx1M+5FgACBzgICoDOw9gQIENiqgADY6mbciwABAp0FBEBnYO0JECCwVQEBsNXNuBcBAgQ6CwiAzsDaEyBAYKsCAmCrm3EvAgQIdBYQAJ2BtSdAgMBWBQTAVjfjXgQIEOgsIAA6A2tPgACBrQocLp780Fbv5l4tBJ65L+vy4SeyetVDBdLfA/BzD0PX1f3wX9/IjvAJIPNSTYAAgTICAqDMKg1CgACBTEAAZF6qCRAgUEZAAJRZpUEIECCQCQiAzEs1AQIEyggIgDKrNAgBAgQyAQGQeakmQIBAGQEBUGaVBiFAgEAmIAAyL9UECBAoIyAAyqzSIAQIEMgEBEDmpZoAAQJlBARAmVUahAABApmAAMi8VBMgQKCMgAAos0qDECBAIBMQAJmXagIECJQROJSZZC+DXL+VTeoL4DOv4tXeDrUX/Nbns/l8Asi8VBMgQKCMgAAos0qDECBAIBMQAJmXagIECJQREABlVmkQAgQIZAICIPNSTYAAgTICAqDMKg1CgACBTEAAZF6qCRAgUEZAAJRZpUEIECCQCQiAzEs1AQIEyggIgDKrNAgBAgQyAQGQeakmQIBAGQEBUGaVBiFAgEAmIAAyL9UECBAoIyAAyqzSIAQIEMgEBEDmpZoAAQJlBPweQJlVXjGIL4C/AqbG04djNoe3Q+Y1W/Vd/8pu7BNA5qWaAAECZQQEQJlVGoQAAQKZgADIvFQTIECgjIAAKLNKgxAgQCATEACZl2oCBAiUERAAZVZpEAIECGQCAiDzUk2AAIEyAgKgzCoNQoAAgUxAAGReqgkQIFBGQACUWaVBCBAgkAkIgMxLNQECBMoICIAyqzQIAQIEMgEBkHmpJkCAQBkBAVBmlQYhQIBAJiAAMi/VBAgQKCPg9wBmW+W9f8xufPO9Wb3qqQSeupFd9x+vz+pVzyVw9z+z+/oEkHmpJkCAQBkBAVBmlQYhQIBAJiAAMi/VBAgQKCMgAMqs0iAECBDIBARA5qWaAAECZQQEQJlVGoQAAQKZgADIvFQTIECgjIAAKLNKgxAgQCATEACZl2oCBAiUERAAZVZpEAIECGQCAiDzUk2AAIEyAgKgzCoNQoAAgUxAAGReqgkQIFBGQACUWaVBCBAgkAkIgMxLNQECBMoI+D2A2VZ586HsxjeeyupVDxV43d+z4x98Mqt/IitXPZnA257PLuwTQOalmgABAmUEBECZVRqEAAECmYAAyLxUEyBAoIyAACizSoMQIEAgExAAmZdqAgQIlBEQAGVWaRACBAhkAgIg81JNgACBMgICoMwqDUKAAIFMQABkXqoJECBQRkAAlFmlQQgQIJAJCIDMSzUBAgTKCAiAMqs0CAECBDIBAZB5qSZAgEAZAQFQZpUGIUCAQCYgADIv1QQIECgj4PcAZlvlMVzZ4TjbhLu+b7reXWMZfrWATwCrCTUgQIDAnAICYM69uTUBAgRWCwiA1YQaECBAYE4BATDn3tyaAAECqwUEwGpCDQgQIDCngACYc29uTYAAgdUCAmA1oQYECBCYU0AAzLk3tyZAgMBqAQGwmlADAgQIzCkgAObcm1sTIEBgtYAAWE2oAQECBOYUEABz7s2tCRAgsFpAAKwm1IAAAQJzCgiAOffm1gQIEFgtIABWE2pAgACBOQXCL5efc8hN3/p7n86u94nHs/oH78nqVTcVeM3LWbt/35nVH36a1asmcCrgE8CphscECBDYkYAA2NGyjUqAAIFTAQFwquExAQIEdiQgAHa0bKMSIEDgVEAAnGp4TIAAgR0JCIAdLduoBAgQOBUQAKcaHhMgQGBHAgJgR8s2KgECBE4FBMCphscECBDYkYAA2NGyjUqAAIFTAQFwquExAQIEdiQgAHa0bKMSIEDgVEAAnGp4TIAAgR0JCIAdLduoBAgQOBUQAKcaHhMgQGBHAoeLT34/G/cHn8rq91b96CPZxA9/J6tPqw/H9C/ULwik3+//Svj9/gtHX/qS9V7K4skzBXwCOBNKGQECBKoJCIBqGzUPAQIEzhQQAGdCKSNAgEA1AQFQbaPmIUCAwJkCAuBMKGUECBCoJiAAqm3UPAQIEDhTQACcCaWMAAEC1QQEQLWNmocAAQJnCgiAM6GUESBAoJqAAKi2UfMQIEDgTAEBcCaUMgIECFQTEADVNmoeAgQInCkgAM6EUkaAAIFqAgKg2kbNQ4AAgTMFBMCZUMoIECBQTeBaPNBnHsv+5Lufzep7V3/jC31P+OI3+/ZPu7/4xuwvjoes/i1/zeq3Vn0r+3+gOy5ejSZ49XpU3r34Iz/OjvjJR7N61XMJZO/+uWZzWwIECBBYEBAACzheIkCAQGUBAVB5u2YjQIDAgoAAWMDxEgECBCoLCIDK2zUbAQIEFgQEwAKOlwgQIFBZQABU3q7ZCBAgsCAgABZwvESAAIHKAgKg8nbNRoAAgQUBAbCA4yUCBAhUFhAAlbdrNgIECCwICIAFHC8RIECgsoAAqLxdsxEgQGBBQAAs4HiJAAEClQUEQOXtmo0AAQILAvnvASw0u/Slz33r0qevfPJwvPKlS19I66/furTNlU9++WtXvlTyhfT3A1L/tD5FTvvf+Up6wq7qH7qZjfujj2X1qscK+AQw1t/pBAgQGCYgAIbRO5gAAQJjBQTAWH+nEyBAYJiAABhG72ACBAiMFRAAY/2dToAAgWECAmAYvYMJECAwVkAAjPV3OgECBIYJCIBh9A4mQIDAWAEBMNbf6QQIEBgmIACG0TuYAAECYwUEwFh/pxMgQGCYgAAYRu9gAgQIjBUQAGP9nU6AAIFhAgJgGL2DCRAgMFZAAIz1dzoBAgSGCRy6n/ztz3c/wgENBd70UsNmWs0ukP68wuzz7u3+PgHsbePmJUCAwP8EBIC3AgECBHYqIAB2unhjEyBAQAB4DxAgQGCnAgJgp4s3NgECBASA9wABAgR2KiAAdrp4YxMgQEAAeA8QIEBgpwICYKeLNzYBAgQEgPcAAQIEdiogAHa6eGMTIEBAAHgPECBAYKcCAmCnizc2AQIEBID3AAECBHYqIAB2unhjEyBA4BoCAgQIXCXw8R9e9crlz/f+/YDHH7783KrPfv1LfSfzCaCvr+4ECBDYrIAA2OxqXIwAAQJ9BQRAX1/dCRAgsFkBAbDZ1bgYAQIE+goIgL6+uhMgQGCzAgJgs6txMQIECPQVEAB9fXUnQIDAZgUEwGZX42IECBDoKyAA+vrqToAAgc0KCIDNrsbFCBAg0FdAAPT11Z0AAQKbFRAAm12NixEgQKCvgADo66s7AQIENisgADa7GhcjQIBAXwEB0NdXdwIECGxWwO8BbHY1LkaAwO0Cjzx6+zPL/9779wnS/tdvLd/39le/8tXbn2n77z4BtPXUjQABAtMICIBpVuWiBAgQaCsgANp66kaAAIFpBATANKtyUQIECLQVEABtPXUjQIDANAICYJpVuSgBAgTaCgiAtp66ESBAYBoBATDNqlyUAAECbQUEQFtP3QgQIDCNgACYZlUuSoAAgbYCAqCtp24ECBCYRkAATLMqFyVAgEBbAQHQ1lM3AgQITCMgAKZZlYsSIECgrYAAaOupGwECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAwEqB/wLSN3Fq/zqzhwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=512x512>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "raster = rasterize_stroke(strokes[2][\"strokePoints\"], 0.5, 0.5, 32, 32)\n",
    "PIL.Image.fromarray(raster).resize((512, 512), PIL.Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "o-FOVdFpgkdf"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "X_RANGE = 0.6\n",
    "Y_RANGE = 0.6\n",
    "\n",
    "def ensure_empty_dir(dirname):\n",
    "  dirpath = Path(dirname)\n",
    "  if dirpath.exists() and dirpath.is_dir():\n",
    "    shutil.rmtree(dirpath)\n",
    "  dirpath.mkdir()\n",
    "\n",
    "def augment_points(points, move_range, scale_range, rotate_range):\n",
    "  move_x = np.random.uniform(low=-move_range, high=move_range)\n",
    "  move_y = np.random.uniform(low=-move_range, high=move_range)\n",
    "  scale = np.random.uniform(low=1.0-scale_range, high=1.0+scale_range)\n",
    "  rotate = np.random.uniform(low=-rotate_range, high=rotate_range)\n",
    "\n",
    "  x_axis_x = math.cos(rotate) * scale\n",
    "  x_axis_y = math.sin(rotate) * scale\n",
    "\n",
    "  y_axis_x = -math.sin(rotate) * scale\n",
    "  y_axis_y = math.cos(rotate) * scale\n",
    "\n",
    "  new_points = []\n",
    "  for point in points:\n",
    "    old_x = point[\"x\"]\n",
    "    old_y = point[\"y\"]\n",
    "    new_x = (x_axis_x * old_x) + (x_axis_y * old_y) + move_x\n",
    "    new_y = (y_axis_x * old_x) + (y_axis_y * old_y) + move_y\n",
    "    new_points.append({\"x\": new_x, \"y\": new_y})\n",
    "\n",
    "  return new_points\n",
    "\n",
    "def save_strokes_as_images(strokes, root_folder, width, height, augment_count):\n",
    "  ensure_empty_dir(root_folder)\n",
    "  labels = set()\n",
    "  for stroke in strokes:\n",
    "    labels.add(stroke[\"label\"].lower())\n",
    "  for label in labels:\n",
    "    label_path = Path(root_folder, label)\n",
    "    ensure_empty_dir(label_path)\n",
    "\n",
    "  label_counts = {}\n",
    "  for stroke in strokes:\n",
    "    points = stroke[\"strokePoints\"]\n",
    "    label = stroke[\"label\"].lower()\n",
    "    if label == \"\":\n",
    "      raise Exception(\"Missing label for %s:%d\" % (stroke[\"filename\"], stroke[\"index\"]))\n",
    "    if label not in label_counts:\n",
    "      label_counts[label] = 0\n",
    "    label_count = label_counts[label]\n",
    "    label_counts[label] += 1\n",
    "    raster = rasterize_stroke(points, X_RANGE, Y_RANGE, width, height)\n",
    "    image = PIL.Image.fromarray(raster)\n",
    "    image.save(Path(root_folder, label, str(label_count) + \".png\"))\n",
    "    for i in range(augment_count):\n",
    "      augmented_points = augment_points(points, 0.1, 0.1, 0.3)\n",
    "      raster = rasterize_stroke(augmented_points, X_RANGE, Y_RANGE, width, height)\n",
    "      image = PIL.Image.fromarray(raster)\n",
    "      image.save(Path(root_folder, label, str(label_count) + \"_a\" + str(i) + \".png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2cmmhBwW9d_p"
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "\n",
    "shuffled_strokes = strokes\n",
    "np.random.shuffle(shuffled_strokes)\n",
    "\n",
    "test_percentage = 10\n",
    "validation_percentage = 10\n",
    "train_percentage = 100 - (test_percentage + validation_percentage)\n",
    "\n",
    "test_count = math.floor((len(shuffled_strokes) * test_percentage) / 100)\n",
    "validation_count = math.floor((len(shuffled_strokes) * validation_percentage) / 100)\n",
    "test_strokes = shuffled_strokes[0:test_count]\n",
    "validation_strokes = shuffled_strokes[test_count:(test_count + validation_count)]\n",
    "train_strokes = shuffled_strokes[(test_count + validation_count):]\n",
    "\n",
    "save_strokes_as_images(test_strokes, \"test\", IMAGE_WIDTH, IMAGE_HEIGHT, 10)\n",
    "save_strokes_as_images(validation_strokes, \"validation\", IMAGE_WIDTH, IMAGE_HEIGHT, 0)\n",
    "save_strokes_as_images(train_strokes, \"train\", IMAGE_WIDTH, IMAGE_HEIGHT, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-Ttfz7LlPil",
    "outputId": "920681dc-fc77-4c8e-aeb9-bdb759470871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 files belonging to 3 classes.\n",
      "Found 3520 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    directory='validation',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(IMAGE_WIDTH, IMAGE_HEIGHT)).prefetch(buffer_size=32)\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory='train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(IMAGE_WIDTH, IMAGE_HEIGHT)).prefetch(buffer_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "Q_vUMVmQn400",
    "outputId": "847d6621-4031-480c-f974-711df6a40aae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "21qi3bLAo80t"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(16, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    activation = \"softmax\"\n",
    "    units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7DjpCkt0qZiy",
    "outputId": "fe3d7104-57e9-4e08-ce74-8648225267cb"
   },
   "outputs": [],
   "source": [
    "model = make_model(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3), num_classes=3)\n",
    "#keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "287Am2coqkQC",
    "outputId": "8d2771fa-86e0-41d4-a3cd-ace1975fcd13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m109/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4109 - loss: 0.6716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.4645 - loss: 0.6277 - val_accuracy: 0.4250 - val_loss: 0.6604 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m106/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5321 - loss: 0.5713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5409 - loss: 0.5643 - val_accuracy: 0.4250 - val_loss: 0.7506 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m109/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5736 - loss: 0.5380"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5807 - loss: 0.5331 - val_accuracy: 0.4250 - val_loss: 0.7201 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m109/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6183 - loss: 0.4967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6241 - loss: 0.4915 - val_accuracy: 0.4250 - val_loss: 0.5916 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m105/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6501 - loss: 0.4613"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6526 - loss: 0.4582 - val_accuracy: 0.6000 - val_loss: 0.4732 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m109/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6995 - loss: 0.4298"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7009 - loss: 0.4245 - val_accuracy: 0.6750 - val_loss: 0.4078 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m109/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7193 - loss: 0.4108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7287 - loss: 0.4030 - val_accuracy: 0.6000 - val_loss: 0.3982 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m106/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7491 - loss: 0.3854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7452 - loss: 0.3858 - val_accuracy: 0.7000 - val_loss: 0.3448 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m104/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7493 - loss: 0.3823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7526 - loss: 0.3739 - val_accuracy: 0.7500 - val_loss: 0.3114 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m107/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7616 - loss: 0.3643"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7670 - loss: 0.3529 - val_accuracy: 0.7750 - val_loss: 0.3047 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m103/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7699 - loss: 0.3423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7722 - loss: 0.3444 - val_accuracy: 0.8250 - val_loss: 0.3036 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m108/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7855 - loss: 0.3413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7957 - loss: 0.3312 - val_accuracy: 0.8750 - val_loss: 0.2831 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m106/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7810 - loss: 0.3311"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7855 - loss: 0.3262 - val_accuracy: 0.8750 - val_loss: 0.2808 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m104/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7893 - loss: 0.3177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8000 - loss: 0.3166 - val_accuracy: 0.8750 - val_loss: 0.2841 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m104/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8190 - loss: 0.3016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8162 - loss: 0.3082 - val_accuracy: 0.8250 - val_loss: 0.3347 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m108/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8101 - loss: 0.3049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8176 - loss: 0.3013 - val_accuracy: 0.7500 - val_loss: 0.2953 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m108/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8222 - loss: 0.2915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8264 - loss: 0.2892 - val_accuracy: 0.7750 - val_loss: 0.2803 - learning_rate: 5.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m107/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8193 - loss: 0.2919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8239 - loss: 0.2906 - val_accuracy: 0.8000 - val_loss: 0.2491 - learning_rate: 5.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8360 - loss: 0.2825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8358 - loss: 0.2802 - val_accuracy: 0.8250 - val_loss: 0.2436 - learning_rate: 5.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m108/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8334 - loss: 0.2798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8287 - loss: 0.2800 - val_accuracy: 0.8250 - val_loss: 0.3133 - learning_rate: 5.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m107/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8405 - loss: 0.2660"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8403 - loss: 0.2708 - val_accuracy: 0.7750 - val_loss: 0.2718 - learning_rate: 5.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m104/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8333 - loss: 0.2682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8338 - loss: 0.2694 - val_accuracy: 0.8500 - val_loss: 0.2390 - learning_rate: 5.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m105/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8256 - loss: 0.2810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8284 - loss: 0.2778 - val_accuracy: 0.8500 - val_loss: 0.2349 - learning_rate: 5.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8333 - loss: 0.2756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8372 - loss: 0.2725 - val_accuracy: 0.8750 - val_loss: 0.2288 - learning_rate: 5.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m104/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8428 - loss: 0.2726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8313 - loss: 0.2787 - val_accuracy: 0.8750 - val_loss: 0.2348 - learning_rate: 5.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m105/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8523 - loss: 0.2528"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8463 - loss: 0.2589 - val_accuracy: 0.9000 - val_loss: 0.2597 - learning_rate: 5.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8447 - loss: 0.2622"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8418 - loss: 0.2639 - val_accuracy: 0.8750 - val_loss: 0.2315 - learning_rate: 5.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8378 - loss: 0.2695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8423 - loss: 0.2625 - val_accuracy: 0.9000 - val_loss: 0.2313 - learning_rate: 2.5000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m103/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8444 - loss: 0.2571"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8474 - loss: 0.2586 - val_accuracy: 0.8750 - val_loss: 0.2261 - learning_rate: 2.5000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m107/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8532 - loss: 0.2569"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8457 - loss: 0.2573 - val_accuracy: 0.8750 - val_loss: 0.2238 - learning_rate: 2.5000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29a7bfbc230>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"checkpoints/save_at_{epoch}.h5\"),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=validation_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocE3kudZq24U",
    "outputId": "b648723c-1321-4178-f6a9-7126cfb9a33e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "0 0.7087657\n"
     ]
    }
   ],
   "source": [
    "def predict_image(model, filename):\n",
    "  img = keras.preprocessing.image.load_img(filename, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "  img_array = keras.preprocessing.image.img_to_array(img)\n",
    "  img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "  predictions = model.predict(img_array).flatten()\n",
    "  predicted_label_index = np.argmax(predictions)\n",
    "  predicted_score = predictions[predicted_label_index]\n",
    "  return (predicted_label_index, predicted_score)\n",
    "  \n",
    "index, score = predict_image(model, \"test/o/3.png\")\n",
    "\n",
    "print(index, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone initialized. Output shape: (None, 64)\n",
      "--- Loading Test Data ---\n",
      "Processing N in Data/final_dataset_800\\test: found 40 files.\n",
      "Processing O in Data/final_dataset_800\\test: found 20 files.\n",
      "Processing W in Data/final_dataset_800\\test: found 20 files.\n",
      "\n",
      "--- Processing Client A ---\n",
      "Processing N in Data/final_dataset_800\\client_A: found 80 files.\n",
      "Processing O in Data/final_dataset_800\\client_A: found 80 files.\n",
      "Successfully generated: client_A_data.h\n",
      "\n",
      "--- Processing Client B ---\n",
      "Processing N in Data/final_dataset_800\\client_B: found 80 files.\n",
      "Processing W in Data/final_dataset_800\\client_B: found 80 files.\n",
      "Successfully generated: client_B_data.h\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Setup Backbone Model\n",
    "# =============================================================================\n",
    "# Extract 64-dim features from the GlobalAveragePooling2D layer (index -3)\n",
    "feature_extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[-3].output)\n",
    "print(f\"Backbone initialized. Output shape: {feature_extractor.output_shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Data Processing Utils\n",
    "# =============================================================================\n",
    "# Label mapping: n=0, o=1, w=2\n",
    "LABEL_MAP = {'n': 0, 'o': 1, 'w': 2, 'N': 0, 'O': 1, 'W': 2}\n",
    "IMG_W, IMG_H = 32, 32\n",
    "\n",
    "def process_dataset(root_dir):\n",
    "    \"\"\"\n",
    "    Reads all JSONs in root_dir (subfolders n, o, w), rasterizes them,\n",
    "    and extracts features using the backbone.\n",
    "    Returns: (features_array, labels_array)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate through subfolders (n, o, w)\n",
    "    for label_name in os.listdir(root_dir):\n",
    "        if label_name.lower() not in LABEL_MAP: continue\n",
    "        \n",
    "        label_val = LABEL_MAP[label_name.lower()]\n",
    "        folder_path = os.path.join(root_dir, label_name)\n",
    "        json_files = glob.glob(os.path.join(folder_path, \"*.json\"))\n",
    "        \n",
    "        print(f\"Processing {label_name} in {root_dir}: found {len(json_files)} files.\")\n",
    "        \n",
    "        for jf in json_files:\n",
    "            try:\n",
    "                with open(jf, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Iterate strokes in single JSON\n",
    "                for stroke in data[\"strokes\"]:\n",
    "                    # Rasterize (using the function defined in previous cells)\n",
    "                    raster = rasterize_stroke(stroke[\"strokePoints\"], 0.6, 0.6, IMG_W, IMG_H)\n",
    "                    \n",
    "                    # Preprocess for model (1, 32, 32, 3)\n",
    "                    img = Image.fromarray(raster).convert(\"RGB\")\n",
    "                    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                    x = np.expand_dims(x, axis=0)\n",
    "                    \n",
    "                    # Extract feature\n",
    "                    feat = feature_extractor.predict(x, verbose=0)[0]\n",
    "                    features.append(feat)\n",
    "                    labels.append(label_val)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {jf}: {e}\")\n",
    "                \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "def write_data_h(filename, train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "    \"\"\"Writes data to a C++ header file matching the template.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(f\"// Data generated for {filename}\\n\")\n",
    "        f.write(\"#include <cstdint>\\n\\n\")\n",
    "        \n",
    "        # Write constants\n",
    "        f.write(f\"const int first_layer_input_cnt = 64;\\n\")\n",
    "        f.write(f\"const int train_data_cnt = {len(train_y)};\\n\")\n",
    "        f.write(f\"const int validation_data_cnt = {len(val_y)};\\n\")\n",
    "        f.write(f\"const int test_data_cnt = {len(test_y)};\\n\")\n",
    "        f.write(f\"const int classes_cnt = 3;\\n\\n\")\n",
    "        \n",
    "        # Helper to write arrays\n",
    "        def write_arr(name, dtype, data, dim=1):\n",
    "            f.write(f\"const {dtype} {name}\")\n",
    "            if dim == 2:\n",
    "                f.write(f\"[{len(data)}][64] = {{\\n\")\n",
    "                for row in data:\n",
    "                    f.write(\"  {\" + \", \".join([f\"{v:.6f}\" for v in row]) + \"},\\n\")\n",
    "            else:\n",
    "                f.write(f\"[{len(data)}] = {{\\n  \")\n",
    "                f.write(\", \".join(map(str, data)))\n",
    "            f.write(\"\\n};\\n\\n\")\n",
    "\n",
    "        # Write Labels\n",
    "        write_arr(\"train_labels\", \"int\", train_y)\n",
    "        write_arr(\"validation_labels\", \"int\", val_y)\n",
    "        write_arr(\"test_labels\", \"int\", test_y)\n",
    "        \n",
    "        # Write Features\n",
    "        write_arr(\"train_data\", \"float\", train_x, dim=2)\n",
    "        write_arr(\"validation_data\", \"float\", val_x, dim=2)\n",
    "        write_arr(\"test_data\", \"float\", test_x, dim=2) # Using float for features\n",
    "        \n",
    "    print(f\"Successfully generated: {filename}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Main Execution\n",
    "# =============================================================================\n",
    "BASE_DATA_DIR = \"Data/final_dataset_800\"\n",
    "\n",
    "# 3.1 Load Global Test Set (Used for both clients)\n",
    "print(\"--- Loading Test Data ---\")\n",
    "test_x, test_y = process_dataset(os.path.join(BASE_DATA_DIR, \"test\"))\n",
    "\n",
    "# 3.2 Process Client A (N, O) -> client_A_data.h\n",
    "print(\"\\n--- Processing Client A ---\")\n",
    "x_a, y_a = process_dataset(os.path.join(BASE_DATA_DIR, \"client_A\"))\n",
    "\n",
    "# Split A: 80% Train, 20% Test\n",
    "idx_a = np.arange(len(y_a))\n",
    "np.random.shuffle(idx_a)\n",
    "split_a = int(len(y_a) * 0.8)\n",
    "train_x_a, val_x_a = x_a[idx_a[:split_a]], x_a[idx_a[split_a:]]\n",
    "train_y_a, val_y_a = y_a[idx_a[:split_a]], y_a[idx_a[split_a:]]\n",
    "\n",
    "write_data_h(\"client_A_data.h\", train_x_a, train_y_a, val_x_a, val_y_a, test_x, test_y)\n",
    "\n",
    "# 3.3 Process Client B (N, W) -> client_B_data.h\n",
    "print(\"\\n--- Processing Client B ---\")\n",
    "x_b, y_b = process_dataset(os.path.join(BASE_DATA_DIR, \"client_B\"))\n",
    "\n",
    "# Split B: 80% Train, 20% Test\n",
    "idx_b = np.arange(len(y_b))\n",
    "np.random.shuffle(idx_b)\n",
    "split_b = int(len(y_b) * 0.8)\n",
    "train_x_b, val_x_b = x_b[idx_b[:split_b]], x_b[idx_b[split_b:]]\n",
    "train_y_b, val_y_b = y_b[idx_b[:split_b]], y_b[idx_b[split_b:]]\n",
    "\n",
    "write_data_h(\"client_B_data.h\", train_x_b, train_y_b, val_x_b, val_y_b, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYyLaqOYtxTH",
    "outputId": "766a130b-53a7-4230-b685-6de0d8d66aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "87.9% correct (N=387, 53 unknown)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "SCORE_THRESHOLD = 0.7\n",
    "\n",
    "correct_count = 0\n",
    "wrong_count = 0\n",
    "discarded_count = 0\n",
    "for label_dir in glob.glob(\"test/*\"):\n",
    "  label = (label_dir.replace(\"test/\", \"\"))\n",
    "  if(label == 'test\\\\n'):\n",
    "    label = 0\n",
    "  if(label == 'test\\\\w'):\n",
    "    label = 2\n",
    "  if(label == 'test\\\\o'):\n",
    "    label = 1\n",
    "  for filename in glob.glob(label_dir + \"/*.png\"):\n",
    "    index, score = predict_image(model, filename)\n",
    "    if score < SCORE_THRESHOLD:\n",
    "      discarded_count += 1\n",
    "      continue\n",
    "    if index == label:\n",
    "      correct_count += 1\n",
    "    else:\n",
    "      wrong_count += 1\n",
    "      # print(\"%s expected, %d found with score %f\" % (label, index, score))\n",
    "      # display(Image(filename=filename))\n",
    "\n",
    "correct_percentage = (correct_count / (correct_count + wrong_count)) * 100\n",
    "print(\"%.1f%% correct (N=%d, %d unknown)\" % (correct_percentage, (correct_count + wrong_count), discarded_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tinymlgen import port\n",
    "\n",
    "# c_code = port(model, variable_name='spell_model', pretty_print=True,optimize=False)\n",
    "# filename = 'net.h'\n",
    "# with open(filename,'w') as f: \n",
    "#    f.write(c_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d26wGJn0t20g",
    "outputId": "b5971e8e-c630-487d-d7ab-b4a4c99aa1a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(SAVED_MODEL_FILENAME+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ki3E7lM_Kr0C",
    "outputId": "038624f6-ba40-4e7a-9474-dbdd75940d90"
   },
   "outputs": [],
   "source": [
    "#!curl -L https://storage.googleapis.com/download.tensorflow.org/models/tflite/micro/magic_wand_saved_model_2021_01_02.tgz -o saved_model.tgz\n",
    "#!tar -xzf saved_model.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-hU8aU24gbL",
    "outputId": "11d2ecc2-509a-46b8-ab02-15e17310b48b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hugo-\\AppData\\Local\\Temp\\tmpibijp886\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hugo-\\AppData\\Local\\Temp\\tmpibijp886\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\hugo-\\AppData\\Local\\Temp\\tmpibijp886'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 64), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2862503802064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503802640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503803984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503804176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503801872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503796880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503803024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503804752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503803216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503804368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503800912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503802832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525056592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525057168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525058512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525058704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525056976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525056208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\hugo-\\AppData\\Local\\Temp\\tmpb0tz845y\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hugo-\\AppData\\Local\\Temp\\tmpb0tz845y\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\hugo-\\AppData\\Local\\Temp\\tmpb0tz845y'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 64), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2862503802064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503802640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503803984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503804176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503801872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503796880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503803024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503804752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503803216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503804368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503800912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862503802832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525056592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525057168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525058512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525058704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525056976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2862525056208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugo-\\anaconda3\\envs\\test2_tut0\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30024"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = tf.keras.Model(inputs=model.input, outputs=model.layers[-3].output)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(backbone)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(FLOAT_TFL_MODEL_FILENAME, \"wb\").write(model_no_quant_tflite)\n",
    "\n",
    "def representative_dataset():\n",
    "  for filename in glob.glob(\"test/*/*.png\"):\n",
    "    img = keras.preprocessing.image.load_img(filename, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis   for images, labels in train_ds.take(1):\n",
    "    yield([img_array])\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(QUANTIZED_TFL_MODEL_FILENAME, \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "w5QZTfwRLFAi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing TFLite Backbone on: test\\n\\0.png\n",
      "------------------------------\n",
      "Output Shape: (64,)\n",
      "Feature Vector (first 10 values):\n",
      "[0.36767024 0.14232397 0.5337149  0.         0.6285975  0.32022893\n",
      " 0.21348596 0.3439496  0.39139092 0.        ]\n",
      "------------------------------\n",
      " Success! The TFLite model outputs a 64-dim vector.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugo-\\anaconda3\\envs\\test2_tut0\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "def predict_backbone_tflite(tflite_model, filename):\n",
    "  img = keras.preprocessing.image.load_img(filename, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "  img_array = keras.preprocessing.image.img_to_array(img)\n",
    "  img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "  # Initialize the TFLite interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  # If required, quantize the input layer (from float to integer)\n",
    "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "  if (input_scale, input_zero_point) != (0.0, 0):\n",
    "    img_array = np.multiply(img_array, 1.0 / input_scale) + input_zero_point\n",
    "    img_array = img_array.astype(input_details[\"dtype\"])\n",
    "  \n",
    "  # Invoke the interpreter\n",
    "  interpreter.set_tensor(input_details[\"index\"], img_array)\n",
    "  interpreter.invoke()\n",
    "  pred = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "  \n",
    "  # If required, dequantized the output layer (from integer to float)\n",
    "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "  if (output_scale, output_zero_point) != (0.0, 0):\n",
    "    pred = pred.astype(np.float32)\n",
    "    pred = np.multiply((pred - output_zero_point), output_scale)\n",
    "  return pred\n",
    "  #predicted_label_index = np.argmax(pred)\n",
    "  #predicted_score = pred[predicted_label_index]\n",
    "  #return (predicted_label_index, predicted_score)\n",
    "# Test on a single image\n",
    "test_files = glob.glob(\"test/*/*.png\")\n",
    "\n",
    "if len(test_files) > 0:\n",
    "    test_image = test_files[0]\n",
    "    print(f\"Testing TFLite Backbone on: {test_image}\")\n",
    "    \n",
    "    # Run prediction\n",
    "    features = predict_backbone_tflite(model_tflite, test_image)\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Output Shape: {features.shape}\")\n",
    "    print(\"Feature Vector (first 10 values):\")\n",
    "    print(features[:10]) # Print first 10 values to verify\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if features.shape == (64,):\n",
    "        print(\" Success! The TFLite model outputs a 64-dim vector.\")\n",
    "    else:\n",
    "        print(\" Warning: Unexpected output shape.\")\n",
    "else:\n",
    "    print(\" No test images found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtee_WxPMgup",
    "outputId": "e27400e5-de03-4b5f-864f-8ecf240a4d39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.04222655e-03, 2.07315058e-01, 0.00000000e+00, 4.07373339e-01,\n",
       "       2.13570073e-02, 1.13472040e-03, 1.01032443e-01, 4.91632335e-03,\n",
       "       0.00000000e+00, 5.62685907e-01, 2.69764841e-01, 3.10607404e-01,\n",
       "       2.27451667e-01, 1.80481374e-01, 4.72173512e-01, 2.70816058e-01,\n",
       "       2.46331349e-01, 4.30485606e-01, 4.56068397e-01, 0.00000000e+00,\n",
       "       6.98417937e-03, 1.09476931e-01, 5.28327584e-01, 2.21225172e-01,\n",
       "       3.36370766e-01, 1.63715391e-03, 2.43979841e-01, 5.05711377e-01,\n",
       "       4.33009684e-01, 4.56355274e-01, 0.00000000e+00, 4.72803384e-01,\n",
       "       5.19158617e-02, 9.45606548e-03, 4.68716562e-01, 2.49107793e-01,\n",
       "       0.00000000e+00, 4.79563922e-01, 3.45538394e-03, 0.00000000e+00,\n",
       "       1.64863691e-02, 2.92334050e-01, 5.93118727e-01, 1.50878012e-01,\n",
       "       3.94553458e-03, 4.39858921e-02, 4.22467850e-02, 3.08856726e-01,\n",
       "       4.80641603e-01, 1.11965346e-04, 4.61262912e-01, 0.00000000e+00,\n",
       "       2.53593326e-01, 4.91987616e-01, 0.00000000e+00, 5.39045572e-01,\n",
       "       1.20942863e-02, 4.05861884e-02, 0.00000000e+00, 8.52027256e-03,\n",
       "       1.32425139e-02, 2.93196589e-01, 0.00000000e+00, 1.40004151e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict_tflite(model_no_quant_tflite, \"test/o/2.png\")\n",
    "predict_backbone_tflite(model_no_quant_tflite, \"test/o/2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rp0LirfN9vB",
    "outputId": "3272e677-7489-461c-bbd1-5fca6ab93b4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.23720661, 0.        , 0.40325123, 0.01186033,\n",
       "       0.        , 0.09488264, 0.        , 0.        , 0.5455752 ,\n",
       "       0.3083686 , 0.36767024, 0.24906695, 0.20162562, 0.4625529 ,\n",
       "       0.24906695, 0.23720661, 0.45069256, 0.43883222, 0.        ,\n",
       "       0.        , 0.13046363, 0.5218545 , 0.24906695, 0.37953058,\n",
       "       0.        , 0.28464794, 0.4981339 , 0.4269719 , 0.43883222,\n",
       "       0.        , 0.47441322, 0.04744132, 0.        , 0.4625529 ,\n",
       "       0.2727876 , 0.        , 0.47441322, 0.        , 0.        ,\n",
       "       0.01186033, 0.32022893, 0.5811562 , 0.17790496, 0.        ,\n",
       "       0.03558099, 0.03558099, 0.29650825, 0.4625529 , 0.        ,\n",
       "       0.43883222, 0.        , 0.28464794, 0.48627356, 0.        ,\n",
       "       0.5218545 , 0.01186033, 0.03558099, 0.        , 0.        ,\n",
       "       0.01186033, 0.32022893, 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_backbone_tflite(model_tflite, \"test/o/2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "NTjGMU8BPpoz",
    "outputId": "fcd585d8-7e97-4f4a-a623-160e74b0505e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TensorFlow</th>\n",
       "      <td>362600 bytes</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorFlow Lite</th>\n",
       "      <td>97804 bytes</td>\n",
       "      <td>(reduced by 264796 bytes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorFlow Lite Quantized</th>\n",
       "      <td>30024 bytes</td>\n",
       "      <td>(reduced by 67780 bytes)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Size                           \n",
       "Model                                                             \n",
       "TensorFlow                 362600 bytes                           \n",
       "TensorFlow Lite            97804 bytes   (reduced by 264796 bytes)\n",
       "TensorFlow Lite Quantized   30024 bytes   (reduced by 67780 bytes)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_size(path):\n",
    "    if os.path.isfile(path):\n",
    "        return os.path.getsize(path)\n",
    "    total_size = 0\n",
    "    for dirpath, _, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "#def get_dir_size(dir):\n",
    "#  size = 0\n",
    "#  for f in os.scandir(dir):\n",
    "#    if f.is_file():\n",
    "#      size += f.stat().st_size\n",
    "#    elif f.is_dir():\n",
    "#      size += get_dir_size(f.path)\n",
    "#  return size\n",
    "\n",
    "# Calculate size\n",
    "size_tf = get_size(SAVED_MODEL_FILENAME+\".h5\")\n",
    "size_no_quant_tflite = get_size(FLOAT_TFL_MODEL_FILENAME)\n",
    "size_tflite = get_size(QUANTIZED_TFL_MODEL_FILENAME)\n",
    "\n",
    "# Compare size\n",
    "pd.DataFrame.from_records(\n",
    "    [[\"TensorFlow\", f\"{size_tf} bytes\", \"\"],\n",
    "     [\"TensorFlow Lite\", f\"{size_no_quant_tflite} bytes \", f\"(reduced by {size_tf - size_no_quant_tflite} bytes)\"],\n",
    "     [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\", f\"(reduced by {size_no_quant_tflite - size_tflite} bytes)\"]],\n",
    "     columns = [\"Model\", \"Size\", \"\"], index=\"Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrvnEJLfR8KU",
    "outputId": "df0c61f6-0a4a-4792-e08a-eef095f820e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' \n",
      "\n",
      "'xxd' \n",
      "\n",
      "'sed' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install xxd if it is not available\n",
    "!apt-get update && apt-get -qq install xxd\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "!xxd -i {QUANTIZED_TFL_MODEL_FILENAME} > {TFL_CC_MODEL_FILENAME}\n",
    "# Update variable names\n",
    "REPLACE_TEXT = QUANTIZED_TFL_MODEL_FILENAME.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_magic_wand_model_data/g' {TFL_CC_MODEL_FILENAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oazLUtBqWzdJ",
    "outputId": "5e50b68f-b3b9-4d60-b454-a2d75c16572c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0x04, 0x00, 0x00, 0x00, 0x4c, 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00,\n",
      "  0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xd0, 0xff, 0xff, 0xff,\n",
      "  0x19, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x19,\n",
      "  0xe0, 0xff, 0xff, 0xff, 0x09, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x09, 0xf0, 0xff, 0xff, 0xff, 0x28, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x28, 0x0c, 0x00, 0x10, 0x00,\n",
      "  0x0f, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03\n",
      "};\n",
      "unsigned int g_magic_wand_model_data_len = 30912;\n"
     ]
    }
   ],
   "source": [
    "# Print the C source file\n",
    "!tail {TFL_CC_MODEL_FILENAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqN2F42PW-uv"
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# labells = []\n",
    "\n",
    "# csvfile_r = open(\"Data/O_first_last.csv\")\n",
    "# csvreader_r = csv.reader(csvfile_r)\n",
    "# for row in csvreader_r:\n",
    "#     labells.append(row[1])\n",
    "\n",
    "# labells.remove(\"last\")\n",
    "# csvfile_r.close()\n",
    "        \n",
    "# i = 0\n",
    "\n",
    "# rows = []\n",
    "\n",
    "\n",
    "\n",
    "# csvfile_w = open(\"Data/O_body_padded.csv\", \"r\")\n",
    "# csvreader_w = csv.reader(csvfile_w)\n",
    "# for row in csvreader_w:\n",
    "#     rows_m = []\n",
    "#     for item in row:\n",
    "#         rows_m.append(item)\n",
    "#     rows_m.append(labells[i])\n",
    "#     i += 1\n",
    "#     rows.append(rows_m)\n",
    "\n",
    "# csvfile_w.close()\n",
    "\n",
    "# with open('Data/O_body_padded_labels.csv', 'w', newline='') as csvfile:\n",
    "#     spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "#                             quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "#     for row in rows:\n",
    "#         spamwriter.writerow(row)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Magic Wand Training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test2_tut0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
